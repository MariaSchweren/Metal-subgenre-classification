{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping \n",
    "- In this Project multiple scraping scripts are used for different band websites as base for the later dataset.\n",
    "\n",
    "## MetalScraper \n",
    "- Main script \n",
    "- The goal of Metalscraper.py is to fetch genre, Bandname and Link for the band-logo font pictures from each band-site. \n",
    "- scraping of the HTML Tree structure is necessary.   \n",
    "## LinkScraper\n",
    "- The Linkscraper is used for scraping a list of links for the dataset from the websites. Those links stand for all the bands which all have a single page on the website. So the goal has to be, to get allthe links in order to fetch all metadata from the band-sites later. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and packages\n",
    "- beautiful soup \n",
    "- requests \n",
    "- urllib\n",
    "- For all libs. and packages see: requirement.txt ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linkscraper script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "varlist = open(\"List.csv\", \"w\")\n",
    "letterlist = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"NBR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varlist: list for only writing-output in Csv-file \"List.csv\" -> output= all Links for all bands to use with the metal scraper script in the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "letterlist: List for all Bandnames categorized by start-letter of their Name on the website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in letterlist:\n",
    "\n",
    "    counter = 200\n",
    "    response = requests.get(f\"https://www.metal-archives.com/label/ajax-list/json/1/l/{letter}?sEcho=1&iColumns=7&sColumns=&iDisplayStart=0&iDisplayLength={counter}&mDataProp_0=0&mDataProp_1=1&mDataProp_2=2&mDataProp_3=3&mDataProp_4=4&mDataProp_5=5&mDataProp_6=6&iSortCol_0=1&sSortDir_0=asc&iSortingCols=1&bSortable_0=false&bSortable_1=true&bSortable_2=true&bSortable_3=true&bSortable_4=true&bSortable_5=false&bSortable_6=true&_=1708260299235\", headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
    "    response_json = response.json()\n",
    "    counter = response_json[\"iTotalRecords\"]\n",
    "    print (counter, letter)\n",
    "\n",
    "    response = requests.get(f\"https://www.metal-archives.com/label/ajax-list/json/1/l/{letter}?sEcho=1&iColumns=7&sColumns=&iDisplayStart=0&iDisplayLength={counter}&mDataProp_0=0&mDataProp_1=1&mDataProp_2=2&mDataProp_3=3&mDataProp_4=4&mDataProp_5=5&mDataProp_6=6&iSortCol_0=1&sSortDir_0=asc&iSortingCols=1&bSortable_0=false&bSortable_1=true&bSortable_2=true&bSortable_3=true&bSortable_4=true&bSortable_5=false&bSortable_6=true&_=1708260299235\", headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
    "    response_json = response.json()\n",
    "    links = response_json[\"aaData\"]       \n",
    "    output_String = letter\n",
    "\n",
    "    for entry in links:\n",
    "        output_String += \";\" + entry[1].split('\"')[1]\n",
    "    varlist.write(output_String + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This website request is used for getting the starting-letter and a counter of how many bands fit withina certain letter-category.   \n",
    "(counter 200 = default for website requests)\n",
    "The f string in the request is used for changing parameters to the variables \"letter\" and \"count\" instead of \"given letter\" and \"given count\". \n",
    "As first response we get a json-object for total records per letter-category. \n",
    "\n",
    "The second request is used to get all total records per letter, with links as output of all http-links for all of the Bands from the request. \n",
    "As output string we get  an empty string but with entry for first letter. \n",
    "\n",
    "The complete output is made by the output string and the links in csv-format into List.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linklist converter\n",
    "- coverts csv to txt fro working with linklist in metal scraper script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompleteLinkList = open(\"Linklist.txt\", \"w\")\n",
    "LinkList = open(\"List.csv\")\n",
    "\n",
    "for line in LinkList:\n",
    "    line = line.rstrip(\"\\n\")\n",
    "    lineArray = line.split(\";\")[1:]\n",
    "    for entry in lineArray:\n",
    "        if entry != \"\":\n",
    "            CompleteLinkList.write(entry + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetalScraper Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "Linklist = open(\"Linklist.txt\")                                                             #opens Linklist \n",
    "Datalist = open(\"Datalist.csv\", \"a\", encoding=\"utf-8\")                                      #opens Datalist with all scraped link, as \"write only\", uses utf8-encoding to encode special characters, unicode was used before but is not sufficent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for line in Linklist:                                                                                        #for every link from linklist:\n",
    "    page = requests.get(line, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})           #get request ato website for the link\n",
    "\n",
    "    if page.status_code == 200:                                                                                 #200 status = go for request from website (OK)\n",
    "        content = page.content                                                                                  \n",
    "\n",
    "    \n",
    "    DOMdocument = BeautifulSoup(content, 'html.parser')                                                         #parse website content with bs4\n",
    "\n",
    "    \n",
    "    name = DOMdocument.find(\"h1\", class_='band_name')                                                           #search for name in html doc\n",
    "    \n",
    "    logo_prior = DOMdocument.find(\"a\",  id=\"logo\")                                                              #search for logo in html doc / gives 'None' back, if no entry found\n",
    "    if logo_prior  != None:                                                                                     #if logo entry found\n",
    "        logo = logo_prior.attrs['href']                                                                         #get link from href\n",
    "    else:\n",
    "        print(f\"{name} has no logo!\")                                                                           #else: print out that the band has no logo\n",
    "        continue                                                                                                #jump over all bands without logo entry -> jumps to start of loop and continue \n",
    "  \n",
    "\n",
    "    Genre = DOMdocument.find_all(['dl','dd'], {'class': \"float_right\"})                                         # find genre in html doc -> marked by d1 & dd -> float right = pagearchitecture frontend (genre on the rioght of the page) \n",
    "    for div in Genre:                                                                                           #find_all returns iterable but only with 1 entry \n",
    "        genre = div.text.split(\"\\n\")[2]                                                                         #takes entry with genre and gives back textliefert enclosed by \\n\n",
    "\n",
    "\n",
    "\n",
    "    print(name.get_text())\n",
    "    print(genre)\n",
    "    print(logo)\n",
    "    Datalist.write(name.get_text()+\";\"+genre+\";\"+logo+\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is Datalist.csv that now holds every band that has a logo wtih the attributes: bandname, genre and logo link "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picture download\n",
    "- to download the pictures from the logolinks a new script is needed \n",
    "- This script provides the download for all pictures and opens up a new folder for every new genre, that is spotted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, urllib3\n",
    "import time\n",
    "import re\n",
    "\n",
    "                                                                                                                                                #read Datalist.csv \n",
    "                                                                                                                                                #{'Connection': 'keep-alive', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'User-Agent': 'python-requests/2.13.0'}\n",
    "\n",
    "Datalist = open(\"Datalist.csv\", encoding=\"utf-8\")                                                                                               #loop für all entries in Datalist\n",
    "for entry in Datalist:                                                                                                                          \n",
    "                                                                                                                                                #parse entries for \";\" \n",
    "    entryArr = entry.split(\";\")                                                                                                                 #Array comes back -> Name Genre Link\n",
    "    bandName = entryArr[0]\n",
    "    genre = entryArr[1]\n",
    "    logo = entryArr[2].rstrip(\"\\n\")                                                                                                             # split Genre for\"/\"\" \n",
    "    genreArr = genre.split(\"/\")\n",
    "\n",
    "    for genre in genreArr:                                                                                                                      #Datastructure(folders)-> is there already a folder for Genre from Array ?\n",
    "        if not os.path.exists(f\"Genres\\{genre}\"):\n",
    "            os.makedirs(f\"Genres\\{genre}\")                                                                                                      #if there's already a folder - take this , if not - create new folder\n",
    "                                                                                                                                                #wenn Ordner -> Datei runterladen und in Ordner speichern\n",
    "        reqAnswer = requests.get(logo, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"},stream = True, timeout=10)\n",
    "        if reqAnswer.status_code != 200:                                                                                                        # entry eventually not found \n",
    "            print(\"download failed\", bandName)\n",
    "                                                                                                                                                # ATTENTION: Sometimes Bandnames cannot be saved as filename cause window doesnt like special chars (e.g. ~ )\n",
    "                                                                                                                                                # change band name and delete all special chars for the filename\n",
    "        if bandName in entryArr[0]:\n",
    "            bandName_new = ''.join(re.findall(r'\\w', bandName))\n",
    "         \n",
    "        fileName = bandName_new + \"_\" + logo.split(\"/\")[-1].split(\"?\")[0]                                                                       # filename is build with Bandname and name from Logolink: /284593.jpg?124 -> bla_284593.jpg\n",
    "        print(fileName)\n",
    "                                                                                                                                                # Download the file bit by bit to save memory\n",
    "        with open(f\"Genres\\{genre}\\{fileName}\", \"wb\") as f:\n",
    "            for chunk in reqAnswer.iter_content(1024):\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covert pictures\n",
    "- to work with all the band logo pictures, we have to convert them in jpgs\n",
    "- the classifier can't work with the picture format GIF due to higher dimensionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# from https://pythonhint.com/post/6698662917296068/pil-convert-gif-frames-to-jpg\n",
    "# and https://pythonexamples.org/python-check-if-path-is-file-or-directory/\n",
    "\n",
    "dataPath = 'Genres'\n",
    "\n",
    "try:\n",
    "    for subdir in os.listdir(dataPath):\n",
    "        current_path = os.path.join(dataPath, subdir)\n",
    "        for file in os.listdir(current_path):\n",
    "            if os.path.isfile(os.path.join(current_path, file)):                                                                                # exclude folders\n",
    "                if file[-3:] == \"gif\":\n",
    "                    with Image.open(os.path.join(current_path, file)) as im:\n",
    "                        if im.format == \"GIF\":\n",
    "                            for frame_num in range(im.n_frames):\n",
    "                                                                                                                                                # select the current frame\n",
    "                                im.seek(frame_num)\n",
    "\n",
    "                                                                                                                                                # create a new JPEG image with the same size and mode as the GIF frame\n",
    "                                jpeg_frame = Image.new('RGB', im.size)\n",
    "\n",
    "                                                                                                                                                # paste the current frame onto the jpeg image\n",
    "                                jpeg_frame.paste(im)\n",
    "\n",
    "                                                                                                                                                # save the jpeg image with a filename that includes the current frame number\n",
    "                                jpeg_filename = str(file).replace(\".gif\",\".jpg\")\n",
    "                                jpeg_frame.save(os.path.join(current_path, jpeg_filename))\n",
    "                                break\n",
    "                        else:                                                                                                                   # format is already jpg\n",
    "                            jpeg_filename = str(file).replace(\".gif\",\".jpg\")\n",
    "                            jpeg_frame.save(os.path.join(current_path, jpeg_filename))\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
